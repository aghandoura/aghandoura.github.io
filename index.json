[{"content":"","date":"24 August 2023","permalink":"/","section":"aghandoura.github.com","summary":"","title":"aghandoura.github.com"},{"content":"","date":"24 August 2023","permalink":"/tags/devops/","section":"Tags","summary":"","title":"DevOps"},{"content":"","date":"24 August 2023","permalink":"/tags/elasticsearch/","section":"Tags","summary":"","title":"Elasticsearch"},{"content":"","date":"24 August 2023","permalink":"/tags/elk/","section":"Tags","summary":"","title":"ELK"},{"content":"","date":"24 August 2023","permalink":"/tags/filebeat/","section":"Tags","summary":"","title":"Filebeat"},{"content":"","date":"24 August 2023","permalink":"/tags/grafana/","section":"Tags","summary":"","title":"Grafana"},{"content":"","date":"24 August 2023","permalink":"/tags/k8s/","section":"Tags","summary":"","title":"k8s"},{"content":"","date":"24 August 2023","permalink":"/tags/kibana/","section":"Tags","summary":"","title":"Kibana"},{"content":"","date":"24 August 2023","permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes"},{"content":"","date":"24 August 2023","permalink":"/tags/logstash/","section":"Tags","summary":"","title":"Logstash"},{"content":"","date":"24 August 2023","permalink":"/tags/loki/","section":"Tags","summary":"","title":"Loki"},{"content":"","date":"24 August 2023","permalink":"/tags/metricbeat/","section":"Tags","summary":"","title":"Metricbeat"},{"content":"","date":"24 August 2023","permalink":"/tags/minikube/","section":"Tags","summary":"","title":"Minikube"},{"content":"","date":"24 August 2023","permalink":"/tags/observability/","section":"Tags","summary":"","title":"Observability"},{"content":"","date":"24 August 2023","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"24 August 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"In the dynamic landscape of modern software development, maintaining the health and performance of complex systems is paramount. Enter observability, is a concept that has gained significant traction in recent years as applications become more intricate and distributed. In this blog post, we\u0026rsquo;ll delve into what observability is, why it\u0026rsquo;s crucial in a distributed system, and explore some popular tools and design patterns used to achieve observability. We then finish with a hands-on exercise of deploying an observability stack in Kubernetes.\nUnderstanding Observability: A Primer # Observability refers to the capability of gaining insights into the internal states of a system by analyzing its external outputs. Unlike monitoring, which typically focuses on specific metrics, observability aims to provide a holistic view of a system\u0026rsquo;s behavior and performance. This concept is particularly relevant in distributed systems due to the inherent complexity and challenges of managing and maintaining such systems. Following are some of its use cases highlighting its significance:\nDiagnosing Issues # In distributed systems, identifying the root causes of problems can prove exceedingly challenging. Observability steps in by providing insights into the interactions, dependencies, and various components at play, leading to quicker and more accurate troubleshooting efforts.\nUnderstanding Performance # Distributed systems can often fall prey to performance bottlenecks that may not be immediately apparent within individual components. Observability tools step in to closely monitor and analyze the holistic performance of the entire system, ensuring optimal user experiences.\nProactive Monitoring # Observability allows for the proactive monitoring of systems. Rather than waiting for failures to manifest, teams can detect anomalies and unusual patterns early on, enabling swift action to mitigate potential issues before they escalate.\nDynamic Environments # Given the prevalence of containers, microservices, and cloud resources, distributed systems frequently experience dynamic scaling. Observability tools are built to adapt to these fluctuations, offering insights into the ever-evolving infrastructure.\nEnd-to-End Insights # A comprehensive perspective of a distributed system is crucial in understanding how diverse components interact to deliver services. Observability provides these end-to-end insights, which are instrumental in maintaining seamless user experiences.\nService-Level Agreements (SLAs) # Meeting SLAs can be a significant challenge in distributed systems. Observability comes to the rescue by closely monitoring metrics that directly impact SLAs, enabling teams to take corrective measures and avert violations.\nScalability # As distributed systems expand, scalability becomes a top concern. Observability tools diligently track performance metrics as systems scale, ensuring the infrastructure remains capable of handling heightened workloads.\nReducing Downtime # Armed with real-time insights and predictive analytics, observability contributes to minimizing downtime. By rapidly identifying issues and facilitating swift responses, it becomes a linchpin in sustaining uninterrupted operations.\nContinuous Improvement # Observability nurtures a culture of continuous improvement. Armed with historical data, teams can optimize performance, learn from past experiences, and make informed decisions for system enhancements.\nData-Driven Decisions # The wealth of observability data becomes a valuable resource for data-driven decisions regarding resource allocation, infrastructure adjustments, and overarching architectural improvements.\nSecurity and Compliance # Observability tools extend their reach to encompass security event monitoring, audit log analysis, and activities tied to regulatory compliance. This translates to a more secure and compliant distributed system.\nFeedback Loop # An integral feedback loop is established between development and operations teams through observability. Developers gain valuable insights into the impact of their code on the system, expediting iterative development cycles and fostering ongoing improvements.\nIn essence, observability empowers engineering, DevOps teams, and system administrators with the insights necessary to ensure the stability, performance, and reliability of intricate distributed systems. This capability equips organizations to effectively manage the intricacies of contemporary architectures and deliver high-caliber services to end-users.\nTools for Observability # Prometheus: A leading open-source monitoring and alerting toolkit, Prometheus scrapes metrics from various components in Kubernetes clusters. It stores and processes these metrics, allowing users to create custom dashboards and set up alerts based on defined thresholds.\nGrafana: Grafana complements Prometheus by offering a flexible visualization platform. It lets you create interactive, customizable dashboards that display Prometheus metrics and other data sources.\nJaeger: For distributed tracing, Jaeger is a popular choice. It helps track requests as they flow through microservices, identifying latency bottlenecks and aiding in root cause analysis.\nLoki: A log aggregation system, Loki assists in storing and exploring logs. It works well with Kubernetes clusters and can be integrated with Prometheus for powerful log-based queries.\nZipkin: Another distributed tracing system that helps gather timing data needed to troubleshoot latency problems in service architectures.\nELK Stack (Elasticsearch, Logstash, Kibana): Elasticsearch is used for storing and indexing logs, Logstash for collecting and processing logs, and Kibana for visualizing and exploring log data.\nDynatrace: A comprehensive observability platform that provides APM, infrastructure monitoring, and real user monitoring (RUM) to give insights into application and infrastructure performance.\nDatadog: A cloud-based monitoring and analytics platform that offers APM, infrastructure monitoring, log management, and synthetic monitoring for distributed systems.\nSysdig: A platform that provides container monitoring, security, and forensics capabilities for containerized and cloud-native environments.\nOpenTelemetry: An open-source project that provides APIs, libraries, agents, and instrumentation to enable observability in applications, helping to generate and collect distributed traces and metrics.\nInstana: A platform that automatically discovers and monitors applications, microservices, and infrastructure, providing real-time insights into the health and performance of distributed systems.\nWavefront: A cloud-native monitoring and analytics platform that offers observability for applications, containers, and infrastructure through metrics, histograms, traces, and span data.\nNew Relic: A commercial observability platform that offers application performance monitoring (APM), infrastructure monitoring, and synthetic testing capabilities for distributed systems.\nDesign Patterns for Observability in Kubernetes # Instrumentation: Injecting code into applications to generate relevant metrics, logs, and traces. This can be done using libraries or frameworks tailored to your language.\nSidecar Pattern: Deploying a separate container (sidecar) within the same pod as your application container to collect metrics, logs, or traces. This approach avoids interfering with your app\u0026rsquo;s core logic.\nAdapter Pattern: Using an adapter to convert telemetry data from one format to another. For instance, converting application logs into metrics that can be easily analyzed.\nGolden Signals: Monitoring four key metrics‚Äîlatency, traffic, errors, and saturation‚Äîto gain a comprehensive understanding of system health and performance.\nService Mesh: Implementing a service mesh like Istio or Linkerd can help manage observability tasks like tracing, traffic control, and encryption, across your microservices architecture.\nHands-on # We explore two observability stacks in Kubernetes first ELK and then we incrementally build one using Grafana tools.\nPrerequisits # Kubernetes cluster # In this Hands-on we will be using a kubespray cluster. Minikube can be used instead.\n\u0026gt;kubectl get nodes NAME STATUS ROLES AGE VERSION kub-1 Ready control-plane 2d23h v1.27.4 kub-2 Ready \u0026lt;none\u0026gt; 2d23h v1.27.4 kub-3 Ready \u0026lt;none\u0026gt; 2d23h v1.27.4 Helm # \u0026gt; curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 \u0026gt; chmod 700 get_helm.sh \u0026gt; ./get_helm.sh ELK Stack on Kubernetes # Deploy Elasticsearch # In my cluster, I am using Rancher local path provisioner\nCreate values.yaml\n# Shrink default JVM heap. esJavaOpts: \u0026#34;-Xmx128m -Xms128m\u0026#34; # Allocate smaller chunks of memory per pod. resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;512M\u0026#34; limits: cpu: \u0026#34;1000m\u0026#34; memory: \u0026#34;512M\u0026#34; # Request smaller persistent volumes and use \u0026#34;local-path\u0026#34; as storageClassName volumeClaimTemplate: accessModes: [ \u0026#34;ReadWriteOnce\u0026#34; ] storageClassName: \u0026#34;local-path\u0026#34; resources: requests: storage: 100M \u0026gt;helm repo add elastic https://helm.elastic.co \u0026gt;helm install elasticsearch elastic/elasticsearch -f ./values.yaml --namespace=elk --namespace=elk --create-namespace --wait For Minikube make sure to enable storage-provisioner addon:\n\u0026gt;minikube addons enable default-storageclass \u0026gt;minikube addons enable storage-provisioner Use the example value.yaml from the helm repo.\n\u0026gt;wget https://raw.githubusercontent.com/LianDuanTrain/Helm3/master/3%20Helm%20Deep%20Dive/elasticsearch/minikube/values.yaml \u0026gt;helm install elasticsearch elastic/elasticsearch -f ./value.yaml --namespace=elk --create-namespace --wait Verify running pods:\n\u0026gt;kubectl get pods -n NAME READY STATUS RESTARTS AGE elasticsearch-master-0 1/1 Running 0 8m52s elasticsearch-master-1 1/1 Running 0 8m52s elasticsearch-master-2 1/1 Running 0 8m52s Expose service:\n\u0026gt;kubectl port-forward -n elk svc/elasticsearch-master 9200 Get elastic username and password\n\u0026gt;kubectl get secrets --namespace=elk elasticsearch-master-credentials -ojsonpath=\u0026#39;{.data.username}\u0026#39; | base64 -d \u0026gt;kubectl get secrets --namespace=elk elasticsearch-master-credentials -ojsonpath=\u0026#39;{.data.password}\u0026#39; | base64 -d Replace username and password in the curl command with the values from the commands above.\n\u0026gt;curl -u \u0026lt;username\u0026gt;:\u0026lt;password\u0026gt;-i -H \u0026#39;Accept:application/json\u0026#39; https://localhost:9200 -k HTTP/1.1 200 OK X-elastic-product: Elasticsearch content-type: application/json content-length: 548 { \u0026#34;name\u0026#34; : \u0026#34;elasticsearch-master-1\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;r6d0vqVEQ7usXXSpKjBxgA\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;8.5.1\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;c1310c45fc534583afe2c1c03046491efba2bba2\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2022-11-09T21:02:20.169855900Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;9.4.1\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;7.17.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;7.0.0\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } Deploy Logstash # Create values.yaml or download it from Logstash helm-repo\nI had to modify the storageclass template and request reduced resources requirements see below:\npersistence: enabled: true logstashConfig: logstash.yml: | http.host: 0.0.0.0 xpack.monitoring.enabled: false logstashPipeline: uptime.conf: | input { exec { command =\u0026gt; \u0026#34;uptime\u0026#34; interval =\u0026gt; 30 } } output { elasticsearch { hosts =\u0026gt; [\u0026#34;https://elasticsearch-master:9200\u0026#34;] user =\u0026gt; \u0026#39;${ELASTICSEARCH_USERNAME}\u0026#39; cacert =\u0026gt; \u0026#39;/usr/share/logstash/config/certs/ca.crt\u0026#39; password =\u0026gt; \u0026#39;${ELASTICSEARCH_PASSWORD}\u0026#39; index =\u0026gt; \u0026#34;logstash\u0026#34; } } extraEnvs: - name: \u0026#34;ELASTICSEARCH_USERNAME\u0026#34; valueFrom: secretKeyRef: name: elasticsearch-master-credentials key: username - name: \u0026#34;ELASTICSEARCH_PASSWORD\u0026#34; valueFrom: secretKeyRef: name: elasticsearch-master-credentials key: password secretMounts: - name: elasticsearch-master-certs secretName: elasticsearch-master-certs path: /usr/share/logstash/config/certs # Shrink default JVM heap. logstashJavaOpts: \u0026#34;-Xmx512m -Xms512m\u0026#34; # Request smaller persistent volumes. volumeClaimTemplate: accessModes: [ \u0026#34;ReadWriteOnce\u0026#34; ] storageClassName: \u0026#34;local-path\u0026#34; resources: requests: storage: 1Gi \u0026gt;helm install logstash elastic/logstash -f ./values.yaml --namespace=elk --wait Verify service:\n\u0026gt;kubectl port-forward svc/elasticsearch-master 9200 \u0026amp; \u0026gt;curl localhost:9200/_cat/indices Handling connection for 8080 HTTP/1.1 200 OK X-elastic-product: Elasticsearch content-type: application/json content-length: 191 [{\u0026#34;health\u0026#34;:\u0026#34;green\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;open\u0026#34;,\u0026#34;index\u0026#34;:\u0026#34;logstash\u0026#34;,\u0026#34;uuid\u0026#34;:\u0026#34;CT54vcBoR0qx4t0PEy4_Rg\u0026#34;,\u0026#34;pri\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;rep\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;docs.count\u0026#34;:\u0026#34;2\u0026#34;,\u0026#34;docs.deleted\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;store.size\u0026#34;:\u0026#34;33.9kb\u0026#34;,\u0026#34;pri.store.size\u0026#34;:\u0026#34;16.9kb\u0026#34;}]‚èé Deploy Kibana # \u0026gt;helm install kibana elastic/kibana --namespace=elk Deploy Filebeat and Metricbeat # helm install filebeat elastic/filebea --namespace=elk Login to Kibana # We first need to expose the Kibana service, this can be done using kubectl port-forward or an ingress\u0026hellip; Here we just edit the Kibana service to be a NodePort:\nkubectl get svc -n elk kibana-kibana -o yaml apiVersion: v1 kind: Service metadata: annotations: meta.helm.sh/release-name: kibana meta.helm.sh/release-namespace: elk creationTimestamp: \u0026#34;2023-08-24T16:12:23Z\u0026#34; labels: app: kibana app.kubernetes.io/managed-by: Helm heritage: Helm release: kibana name: kibana-kibana namespace: elk resourceVersion: \u0026#34;509386\u0026#34; uid: 3dd813f1-e900-4e50-a054-ebc8aeaff529 spec: clusterIP: 10.233.44.71 clusterIPs: - 10.233.44.71 externalTrafficPolicy: Cluster internalTrafficPolicy: Cluster ipFamilies: - IPv4 ipFamilyPolicy: SingleStack ports: - name: http nodePort: 30000 port: 5601 protocol: TCP targetPort: 5601 selector: app: kibana release: kibana sessionAffinity: None type: NodePort status: loadBalancer: {} Username: elastic `Password``: can be retreived using the command below:\nkubectl get secrets --namespace=elk elasticsearch-master-credentials -ojsonpath=\u0026#39;{.data.password}\u0026#39; | base64 -d After login navigate to Observability, Logs and Metrics should be available\nELK Helm charts archived # Elastic stack helm charts github repository has been archived. with a recommendation to use Elastic Cloud on Kubernetes (ECK).\nGrafana Loki Prometheus Linkerd Mimir # TODO\u0026hellip;\nConclusion # Observability is not just a buzzword; it\u0026rsquo;s a fundamental practice for maintaining and enhancing the performance of complex Kubernetes environments. By employing tools like ELK, Prometheus, Grafana, Jaeger, and Loki, and leveraging design patterns such as instrumentation, sidecar, and adapter, you can build a robust observability strategy that empowers your DevOps team to identify, diagnose, and rectify issues efficiently. As Kubernetes continues to be a cornerstone of modern infrastructure, embracing observability is a strategic move that ensures the seamless operation of your applications and services.\n","date":"24 August 2023","permalink":"/posts/observability/","section":"Posts","summary":"In the dynamic landscape of modern software development, maintaining the health and performance of complex systems is paramount.","title":"The Power of Observability"},{"content":" Introdutction # Traefik is a HTTP reverse proxy and load balancer. In this post, we first present some useful concepts, Introduce Traefik and then proceed with a practical hands-on guide to deploying it in a Kubernetes environment.\nUnderstanding HTTP Reverse Proxy # Before delving into Traefik\u0026rsquo;s intricacies, let\u0026rsquo;s establish a solid understanding of what an HTTP reverse proxy is. Essentially, a reverse proxy serves as an intermediary server between client requests and backend servers. When a client initiates a request to access a web application, the reverse proxy forwards that request to the appropriate backend server. This mechanism offers several advantages, including:\nEnhanced Security: A reverse proxy can effectively shield your network\u0026rsquo;s internal structure by adding an extra layer of security, thus avoiding direct exposure of backend servers to the public internet.\nOptimized Load Distribution: By steering incoming requests towards various backend services, a reverse proxy adeptly distributes the workload, preventing any single service from becoming inundated with traffic.\nCaching and Compression: Reverse proxies are equipped to cache frequently accessed content, thereby alleviating the pressure on backend services and subsequently improve response times for end-users.\nStreamlined SSL Termination: SSL certificates can be managed by the reverse proxy, facilitating the process of securing communications between clients and backend servers.\nUnderstanding Load Balancing # Load balancing stands as a strategic approach aimed at distributing incoming network traffic across multiple services. Its core objective is to fine-tune resource consumption, maximize data throughput, and minimize response latency. Load balancers function to guarantee that no individual service bears an excessive traffic load, thereby enhancing both the availability and reliability of applications.\nIntroducing Traefik # Traefik has carved a niche for itself as a dynamic HTTP reverse proxy and load balancer. What truly sets Traefik apart is its innate ability to autonomously discover and configure backend services as they are rolled out. With support spanning various backends such as Docker, Kubernetes, and Mesos, Traefik\u0026rsquo;s distinct features include:\nSeamless Service Discovery: Traefik boasts the prowess to dynamically detect novel services and seamlessly adjust routing configurationsa trait particularly valuable in containerized and cloud-native settings.\nEfficient Routing and Load Balancing: Traefik diligently routes incoming requests to suitable backend service instances, ensuring an equitable distribution of traffic.\nAutomated SSL Management: Traefik takes the reins in provisioning and overseeing SSL certificates from Let\u0026rsquo;s Encrypt, effectively streamlining the process of enabling HTTPS for your applications.\nMiddleware Support: By offering a suite of middleware features including authentication, rate limiting, and URL rewriting, Traefik empowers you to integrate essential functionalities into your services.\nDeploying Traefik in Kubernetes: A Quick Start Guide using minikube # Now, let\u0026rsquo;s dive into the practical aspect of using Traefik in a Kubernetes environment. Ensure you have a Kubernetes cluster up and running. To simplify the process we will use minikube here: Follow these steps to get started:\nInstallation # curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube setting up the cluster # Start minikube:\nminikube start Install kubectl or use minikube\nalias kubectl=\u0026#34;minikube kubectl --\u0026#34;alias kubectl= kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready control-plane 24m v1.27.3 When working behind a proxy make sure that minikube ip is in no_proxy.\nminikube ip 192.168.39.128 export no_proxy=$no_proxy,192.168.39.0/24 Install Helm # Helm is a package manager for Kubernetes that simplifies the deployment of applications.\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh Install an example application # This is the application that we want to expose using Traefik we can use an Nginx webserver, see installation instructions here, Or chose a wordpress deployment:\nhelm install my-website \\ --set wordpressPassword=password \\ --set mariadb.auth.rootPassword=secretpassword \\ oci://registry-1.docker.io/bitnamicharts/wordpress The service is already exposed as a LoadBalancer service type and can be accessed using:\nminikube service my-website-wordpress --https |-----------|----------------------|-------------|-----------------------------| | NAMESPACE | NAME | TARGET PORT | URL | |-----------|----------------------|-------------|-----------------------------| | default | my-website-wordpress | http/80 | http://192.168.39.128:32376 | | | | https/443 | http://192.168.39.128:30439 | |-----------|----------------------|-------------|-----------------------------| In a browser use urls from the command above https://192.168.39.128:30439 or http://192.168.39.128:32376 to access the wordpress blog example:\nInstall Traefik using Helm # Now to benefit from a reverse proxy we continue with deploying Traefik, run the following commands to install Traefik:\nhelm repo add traefik https://helm.traefik.io/traefik helm repo update helm install traefik traefik/traefik --set ingressRoute.dashboard.enabled=true --set ingressRoute.dashboard.entryPoints=\u0026#34;{web,websecure}\u0026#34; Verify that traefik has been deployed successfully, the dashboard has been exposed using the set arguments in the helm install command above:\nNote:\nMake sure to use the right traefik service node port depending on http or https traffic. (see metalLB section below to avoid that)\nDon\u0026rsquo;t forget to add \u0026ldquo;/\u0026rdquo; after dashboard in the path.\nExpose application using traefik # Let\u0026rsquo;s try a simple UC where you have mulltiple services in your cluster and you want to access them using different custom domains lets do that with our blog:\nFirst we need to append myblog.minikube to /etc/hosts\nminikube ip 192.168.39.128 echo \u0026#34;192.168.39.128 myblog.minikube\u0026#34; | sudo tee -a /etc/hosts Create an IngressRoute for our blog:\napiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: myblog spec: entryPoints: - web routes: - kind: Rule match: Host(`myblog.minikube`) services: - name: my-website-wordpress port: 80 In our case the application we are using is offering a secure endpoint but even if it doesn\u0026rsquo;t we can rely on traefik to do that. We just need to change the entrypoint! see tls section in traefik documentation on how to configure tls\napiVersion: traefik.containo.us/v1alpha1 kind: IngressRoute metadata: name: myblog spec: entryPoints: - websecure routes: - kind: Rule match: Host(`myblog.minikube`) services: - name: my-website-wordpress port: 80 (Optional) Use MetalLB for getting a Loadbalancer IP # You may have noticed that we are using nodeport to access the traefik service and we need to append the port with each domain, this is because we don\u0026rsquo;t have a load balancer ip. See the pending in EXTERNAL-IP. this\nkubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 3d23h my-website-mariadb ClusterIP 10.99.218.197 \u0026lt;none\u0026gt; 3306/TCP 3d22h my-website-wordpress LoadBalancer 10.100.12.50 \u0026lt;pending\u0026gt; 80:32376/TCP,443:30439/TCP 3d22h traefik LoadBalancer 10.108.140.180 \u0026lt;pending\u0026gt; 80:32392/TCP,443:30808/TCP 29h In minikube this can easily be fixed using MetalLB:\nminikube addons enable metallb ‚ùó metallb is a 3rd party addon and is not maintained or verified by minikube maintainers, enable at your own risk. ‚ùó metallb does not currently have an associated maintainer. ‚ñ™ Using image quay.io/metallb/speaker:v0.9.6 ‚ñ™ Using image quay.io/metallb/controller:v0.9.6 üåü The \u0026#39;metallb\u0026#39; addon is enabled Then we need to configure a range for the Load Balancer IP here we chose (192.168.39.10-20 range):\nminikube addons configure metallb -- Enter Load Balancer Start IP: 192.168.39.10 -- Enter Load Balancer End IP: 192.168.39.20 ‚ñ™ Using image quay.io/metallb/speaker:v0.9.6 ‚ñ™ Using image quay.io/metallb/controller:v0.9.6 ‚úÖ metallb was successfully configured Now we can see that Traefik get an IP we can use to access our application:\nkubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 4d my-website-mariadb ClusterIP 10.99.218.197 \u0026lt;none\u0026gt; 3306/TCP 3d22h my-website-wordpress LoadBalancer 10.100.12.50 192.168.39.10 80:32376/TCP,443:30439/TCP 3d22h traefik LoadBalancer 10.108.140.180 192.168.39.11 80:32392/TCP,443:30808/TCP 29h we can now use the service ip instead of the node ip in /etc/hosts: 192.168.39.11 myblog.minikube\nAnd our blog can now be reached using just the doamin name.\nThis is only scratching the surface of what traefik can do. check the docs for more advanced feature.\nTraefik Alternatives # While Traefik is a powerful tool, it\u0026rsquo;s important to explore alternatives that might better suit specific use cases or preferences. Some popular alternatives to Traefik include:\nNginx: A widely used web server, reverse proxy, and load balancer known for its performance, configurability, and extensive module support.\nHAProxy: A fast and reliable solution with advanced load balancing algorithms, suitable for high-traffic environments.\nEnvoy: A modern proxy designed for cloud-native applications, offering features like automatic service discovery and advanced load balancing.\nCaddy: A lightweight web server and reverse proxy with automatic HTTPS capabilities and a simple configuration syntax.\nConclusion # In conclusion, understanding the concepts of HTTP reverse proxies and load balancing is essential for maintaining the stability, scalability, and security of modern web applications. Traefik, along with its alternatives, provides an array of solutions to meet the diverse needs of developers and system administrators. Whether you choose Traefik or another tool, the key lies in selecting the one that aligns with your specific requirements and technical environment.\n","date":"14 August 2023","permalink":"/posts/traefik-kubernetes/","section":"Posts","summary":"Introdutction # Traefik is a HTTP reverse proxy and load balancer.","title":"Exploring Traefik in kubernetes"},{"content":"","date":"14 August 2023","permalink":"/tags/traefik/","section":"Tags","summary":"","title":"Traefik"},{"content":"","date":"3 August 2023","permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI"},{"content":"","date":"3 August 2023","permalink":"/tags/dall-e/","section":"Tags","summary":"","title":"DALL-E"},{"content":"","date":"3 August 2023","permalink":"/tags/dream-studio/","section":"Tags","summary":"","title":"Dream Studio"},{"content":"","date":"3 August 2023","permalink":"/tags/midjourney/","section":"Tags","summary":"","title":"Midjourney"},{"content":" Introduction # In recent years, artificial intelligence (AI) has brought forth a remarkable transformation in the world of digital art and creativity. One of the fascinating aspects of AI\u0026rsquo;s creative capabilities is the generation of lifelike images. These AI-generated images have opened up new frontiers for artists, designers, and content creators, revolutionizing the creative process. In this blog post, we will delve into the world of AI-generated images, exploring how they are created, their applications, and the implications of this creative revolution.\nWhat are AI-Generated Images? # AI-generated images are digital visuals created by artificial intelligence systems using complex algorithms and deep learning techniques. These AI models, particularly Generative Adversarial Networks (GANs), have become the driving force behind generating compelling, realistic images. GANs consist of two neural networks: the generator, which creates images, and the discriminator, which evaluates the authenticity of those images. Through a continuous feedback loop, GANs refine their creations until they produce images that closely resemble real-world photographs.\nThe Creative Process of AI-Generated Images # The creative process of AI-generated images is both fascinating and mysterious. It begins with the training of GANs on vast datasets of real images. As the generator learns to produce new images, the discriminator provides feedback, pushing the generator to improve its creations continuously. This adversarial relationship between the two networks is what drives the refinement of the generated images. With each iteration, the AI model learns and evolves, ultimately producing images that possess stunning levels of detail, realism, and artistic flair.\nApplications of AI-Generated Images # The applications of AI-generated images span across various industries and creative fields:\nArt and Design: AI-generated images have become a powerful tool for artists and designers to explore new styles and concepts. These AI models can create artworks that blend various artistic styles, resulting in captivating and innovative pieces.\nContent Creation: In the realm of content creation, AI-generated images offer a wealth of possibilities. From generating visuals for blog posts and social media to creating unique illustrations and infographics, AI-generated images streamline the creative process and inspire content creators.\nVideo Games and Animation: AI-generated images have found their way into the gaming and animation industries. Game developers use AI-generated assets to enhance virtual environments, while animators leverage AI-generated characters and backgrounds to streamline production.\nStock Photography: AI-generated images provide a vast pool of unique stock photography options, allowing businesses and content creators to find fresh and eye-catching visuals for their projects.\nSome Popular AI Image Generators # DALL-E 2 # The most known and advanced generator available, maybe a bit overhyped. It\u0026rsquo;s very easy to use and generate realistic and detailed images. Openai continue to add powerfull features like the image editor.\nCost: 115 credits cost 15$.\nCheck Openai website for the latest pricing details..\nDream Studio # A budget friendly alternative to DALL-2 and powered by Stable Diffusion an open-source model!\nCost: Free trial credit and then ~5000 image 10$.\nExample using this prompt (SDXL v1.0): Cute dear eating ice cream # Previous Nextsads Midjourney # It is accessible using discord and provide very hight quality image. At this time a free trial is not available. Cost: ~200 credit cost 10$ billed monthly or 8$ billed yearly\nBing Image Creator # Microsoft Image creator based on DALL-E it\u0026rsquo;s still in preview and provide a free plan with limited \u0026ldquo;boosts\u0026rdquo; (faster generation).\nExample using this prompt: Cute dear eating ice cream # Previous Nextsads Selection Criteria # Selecting the perfect one for your needs can be a challenging endeavor. Here are few key features to consider:\nEase of Use: A user-friendly interface can make all the difference in your creative experience. Seek generators that are accessible to both tech-savvy artists and newcomers alike.\nImage Quality: Assess the generator\u0026rsquo;s capability in producing clear, detailed, and realistic images.\nCustomization: Seek generators that empower you with complete control over the final result. Can you specify the style, composition, variations\u0026hellip;\nCost: Explore the options that align with your financial preferences. Is there a free or cost-effective choices available.\nEthical Considerations # Despite their creative potential, AI-generated images also raise ethical concerns. The increasing realism of these images blurs the line between real and fake, potentially leading to misinformation and deepfake-related issues. It is crucial to use AI-generated images responsibly and be transparent about their origin to maintain ethical standards.\nConclusion # AI-generated images mark a new era in creativity, showcasing the tremendous potential of artificial intelligence in the realm of digital art and design. As technology continues to advance, we can expect AI models to create even more breathtaking and thought-provoking visuals. Nevertheless, it is essential to approach this creative revolution with caution, ensuring ethical use and responsible deployment of AI-generated images. By embracing AI\u0026rsquo;s capabilities responsibly, we can unlock a world of endless creative possibilities and push the boundaries of human imagination.\n","date":"3 August 2023","permalink":"/posts/ai-image-generators/","section":"Posts","summary":"Introduction # In recent years, artificial intelligence (AI) has brought forth a remarkable transformation in the world of digital art and creativity.","title":"The Rise of AI-Generated Images: A Creative Revolution"},{"content":"# about\n","date":"1 January 0001","permalink":"/about/","section":"aghandoura.github.com","summary":"# about","title":""},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/series/","section":"Series","summary":"","title":"Series"}]